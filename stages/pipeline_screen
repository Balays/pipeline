#!/usr/bin/env perl 

use strict;
use warnings;
no warnings('once');

use Pipeline;
use Pipeline_Conf;

use Getopt::Long;
use File::Copy;
use File::Basename;
use POSIX qw(strftime);
umask 000;

my $stage_name="screen";
my $stage;
for my $s (@{$Pipeline_Conf::pipeline->{'default'}}){
  $stage = $s if $s->{name} eq $stage_name; 
}
my $stage_id  = $stage->{id};
my $revision  = "0";
my $version   = $Pipeline_Conf::pipeline_version.".".$revision;
my $index_dir = $Pipeline_Conf::bowtie_indexes;
my $index_ids = $Pipeline_Conf::bowtie_stageid;
my $runcmd    = "bowtie";

# options
my $job_num    = "";
my $fasta_file = "";
my $index      = "";
my $threads    = "";
my $run_bowtie = 1;
my $ver     = "";
my $help    = "";
my $options = GetOptions ("job=i"        => \$job_num,
			  "fasta=s"      => \$fasta_file,
			  "indexes=s"    => \$index,
			  "threads=i"    => \$threads,
			  "run_bowtie=i" => \$run_bowtie,
			  "version"      => \$ver,
			  "help"         => \$help,
			 );

if ( $ver ) {
  print STDERR "$stage_name - $version - $stage_id\n";
  exit(0);
} elsif ( $help or !($job_num and $fasta_file) ) {
  print STDERR "Usage: pipeline_$stage_name -j <job number> -f <fasta file> -t <threads> -i <bowtie indexes> -r <run bowtie>\n";
  exit(1);
} 

unless ( $threads ) {
  $threads = 1;
}

my $log = Pipeline::logger($job_num);

unless (-s $fasta_file) {
  $log->error("file: $fasta_file does not exist or is empty");
  exit(1);
}

$log->info("Starting $stage_name ".$index." on job: $job_num");

# update jobcache stage status
Pipeline::update_stage_info($job_num, $stage_name, "running");

my $job_dir     = $Pipeline_Conf::global_job_dir."/".$job_num;
my $proc_dir    = $job_dir."/proc";
my $stage_dir   = $proc_dir."/".$stage_id.".".$stage_name;
my $results_dir = $job_dir."/".$Pipeline_Conf::results_dir;
my $run_dir     = $stage_dir;
my $hostname    = `hostname`;
chomp $hostname;

if (! $run_bowtie) {
  copy($fasta_file, "$results_dir/$stage_id.$stage_name.passed.fna") or fail($log, "Failed copy $fasta_file - $!");

  open(INFO,">$results_dir/$stage_id.$stage_name.info");
  print INFO "# MG-RAST - $stage_name v$version - (".(strftime "%b %e %Y", localtime).")\n";
  print INFO "# site : metagenomics.anl.gov\n# email: mg-rast\@mcs.anl.gov\n";
  print INFO "skipping bowtie screening\n";
  close(INFO);

  $log->info("Finished $stage_name $index on job: $job_num");
  Pipeline::update_stage_info($job_num, $stage_name, "completed");
  exit(0);
}

# create directories
if (-d $stage_dir) {
  my $t = time;
  $log->info("found $stage_dir, moving to $stage_dir.$t");
  move($stage_dir, $stage_dir.".".$t) or fail($log, "$!");
}
mkdir($stage_dir) or fail($log, "Could not mkdir: $stage_dir, $!");

# set cluster workspace dir
if (-d $Pipeline_Conf::cluster_workspace) {
  $run_dir = $Pipeline_Conf::cluster_workspace . "/$job_num.$stage_id.$stage_name";
  if (-d $run_dir) {
    system("rm -rf $run_dir");
  }
  mkdir($run_dir) or fail($log, "Could not mkdir: $run_dir, $!");
  system("echo $hostname > $stage_dir/hostname");
}
$log->info("Running on host $hostname, using dir $run_dir");

my $sort_dir    = (-d $Pipeline_Conf::local_tmp) ? $Pipeline_Conf::local_tmp : ((-d $Pipeline_Conf::cluster_tmp) ? $Pipeline_Conf::cluster_tmp : $run_dir);
my $input_file  = "";
my $input_fasta = $stage_id.".".$stage_name.".input.fna";

system("cp $fasta_file $run_dir/$input_fasta > $run_dir/cp.out 2>&1") == 0 or fail($log, "Screen: cp failed on job: $job_num, see $stage_dir/cp.out for details.");

# deal with bowtie only being able to handle 1024 bp read
system("seqUtil --bowtie_truncate -i $run_dir/$input_fasta -o $run_dir/bowtie.input >> $run_dir/sequtil.out 2>&1") == 0 or fail($log, "Screen: seqUtil failed on job: $job_num, see $stage_dir/sequtil.out for details.");
system("diff $run_dir/$input_fasta $run_dir/bowtie.input > $run_dir/input.diff");
if ( -s $run_dir."/input.diff" > 0 ) {
  system("seqUtil --sortbyid -t $sort_dir -i $fasta_file -o $run_dir/input.sorted >> $run_dir/sequtil.out 2>&1") == 0 or fail($log, "Screen: seqUtil failed on job: $job_num, see $stage_dir/sequtil.out for details.");
  $input_file = "$run_dir/bowtie.input";
} else {
  $input_file = "$run_dir/$input_fasta";
  unlink("$run_dir/bowtie.input");
}

# check indexes
my @indexes = split(/,/, $index);
for my $i (@indexes) {
  unless ( defined $index_ids->{$i} ) {
    fail($log, "$stage_name called with unknown index: ".$i." on job: $job_num. Please update Pipeline_Conf.pm.");
  }
}

for my $index_name (@indexes) {
  my $unaligned_reads = $index_ids->{$index_name}.".".$stage_name.".".$index_name.".passed.fna";
  my $aligned_reads   = $index_ids->{$index_name}.".".$stage_name.".".$index_name.".removed.fna";
  my $aligned_ids     = $index_ids->{$index_name}.".".$stage_name.".".$index_name.".removed.ids";
  my $info_file       = $index_ids->{$index_name}.".".$stage_name.".".$index_name.".info";
  my $out_file        = $index_ids->{$index_name}.".".$stage_name.".".$index_name.".out";

  open(INFO, ">".$run_dir."/".$info_file);
  print INFO "# MG-RAST - ".$stage_name." v".$version." - (".(strftime "%b %e %Y", localtime).")\n";
  print INFO "# site : metagenomics.anl.gov\n# email: mg-rast\@mcs.anl.gov\n";
  print INFO "$runcmd --suppress 5,6 -p $threads -t $index_name\n";
  close(INFO);

  system("$runcmd --suppress 5,6 -p $threads --al $run_dir/$aligned_reads --un $run_dir/$unaligned_reads -f -t $index_dir/$index_name $input_file > $run_dir/$aligned_ids 2> $run_dir/$out_file") == 0 or fail($log, "$runcmd $fasta_file $index failed on job: $job_num, see $stage_dir/$out_file for details."); 

  unless (-e $run_dir."/".$aligned_reads ) {
    unlink($run_dir."/".$aligned_ids);
  }
  $input_file = $run_dir."/".$unaligned_reads;
}

my $passed_seq = $stage_id.".".$stage_name.".passed.fna";

if ((-e $run_dir."/bowtie.input") and (-e $run_dir."/input.sorted")) {
  system("cat $run_dir/*.removed.ids | cut -f1 | sort -u > $run_dir/removed.ids");
  system("seqUtil --remove_seqs -i $run_dir/input.sorted -o $run_dir/$passed_seq -l $run_dir/removed.ids >> $run_dir/sequtil.out 2>&1") == 0 or fail($log, "Screen: seqUtil failed on job: $job_num, see $stage_dir/sequtil.out for details.");
} else {
  system("cp $input_file $run_dir/$passed_seq >> $run_dir/cp.out 2>&1") == 0 or fail($log, "Screen: cp failed on job: $job_num, see $stage_dir/cp.out for details.");
}

# copy output to somewhere
move("$run_dir/$passed_seq", "$results_dir/$passed_seq") or fail($log, "Failed copy $passed_seq - $!");
system("mv $run_dir/*.removed.fna $results_dir/.");
system("mv $run_dir/*.info $results_dir/.");

if ($run_dir ne $stage_dir) {
  system("mv $run_dir/*.out $stage_dir/.");
  system("rm -rf $run_dir") == 0 or fail($log, "$stage_name failed on job: $job_num, can not remove $run_dir");
} else {
  my @run_files = `ls $run_dir`;
  chomp @run_files;
  map { system("rm $run_dir/$_") } grep { $_ !~ /\.out$/ } @run_files;
}

open(INFO, ">".$results_dir."/".$stage_id.".".$stage_name.".info");
print INFO "# MG-RAST - ".$stage_name." v".$version." - (".(strftime "%b %e %Y", localtime).")\n";
print INFO "# site : metagenomics.anl.gov\n# email: mg-rast\@mcs.anl.gov\n";
print INFO "Reads were screening using bowtie against the following index(s) ".$index.".\n";
close(INFO);

chmod 0666, $results_dir."/".$stage_id.".".$stage_name.".info";
chmod 0666, $results_dir."/".$passed_seq;
system("chmod 666 $results_dir/*.$stage_name.*.removed.fna");
system("chmod 666 $results_dir/*.$stage_name.*.info");

$log->info("Finished $stage_name ".$index." on job: $job_num");

# update jobcache stage status
Pipeline::update_stage_info($job_num, $stage_name, "completed");
exit(0);

sub fail {
  my ($log, $message) = @_;
  Pipeline::update_stage_info($job_num, $stage_name, "error");
  $log->error($message);
  if ($run_dir ne $stage_dir) {
    system("mv $run_dir/* $stage_dir/.");
    system("rmdir $run_dir");
  }
  exit(1);
}
