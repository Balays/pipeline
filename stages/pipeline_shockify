#!/usr/bin/env perl 

use strict;
use warnings;
no warnings('once');

use Pipeline;
use Pipeline_Conf;

use Getopt::Long;
use File::Copy;
use POSIX qw(strftime);
umask 000;

my $stage_name = "shockify";
my $stage_id = "999";
my $revision = "0";
my $version  = $Pipeline_Conf::pipeline_version.".".$revision;

# options
my $job_num = "";
my $public  = "";
my $ver     = "";
my $help    = "";
my $options = GetOptions(
    "job=i"   => \$job_num,
        "public"  => \$public,
	"version" => \$ver,
	"help"    => \$help
);

if ($ver) {
  print STDOUT "pipeline_$stage_name - $version\n";
  exit(0);
} elsif ($help || (! $job_num)) {
  print STDERR "Usage: pipeline_$stage_name -j <job number> [-p]\n";
  exit(1);
} 

my $log = Pipeline::logger($job_num);
my $job_dir  = $Pipeline_Conf::global_job_dir."/".$job_num;
my $proc_dir = $job_dir."/proc";
my $run_dir  = $proc_dir."/".$stage_id.".".$stage_name;
my $temp_dir = $Pipeline_Conf::local_workspace;
my $hostname = `hostname`;
chomp $hostname;

# update jobcache stage status
$log->info("Starting $stage_name on job: $job_num");
Pipeline::update_stage_info($job_num, $stage_name, "running");

# create directories
if (-d $run_dir) {
  my $t = time;
  $log->info("found $run_dir, moving to $run_dir.$t");
  move($run_dir, $run_dir.".".$t) or fail($log, "$!");
}
mkdir($run_dir) or fail($log, "Could not mkdir: $run_dir, $!");
$log->info("Running on host $hostname, using dir $run_dir");

my $pflag = $public ? " -p" : "";

# load files and info to shock
$log->info("Loading files to shock");
my $load = system("job2shock.py -d".$pflag." -t $temp_dir -j $job_num > $temp_dir/$job_num.load.out 2> $temp_dir/$job_num.load.err");
if ($load != 0) {
    my $err = `cat $temp_dir/$job_num.load.err`;
    fail($log, $err);
}

# create subset indexes
$log->info("Calculating subset indexes");
my $index = system("job_seq_index.py -m 10 -t $temp_dir -j $job_num > $temp_dir/$job_num.index.out 2> $temp_dir/$job_num.index.err");
if ($index != 0) {
    my $err = `cat $temp_dir/$job_num.index.err`;
    fail($log, $err);
}

# load subsets to shock
$log->info("Loading subset indexes to shock");
my $subset = system("job2shock_subset.py -d".$pflag." -t $temp_dir -j $job_num > $temp_dir/$job_num.subset.out 2> $temp_dir/$job_num.subset.err");
if ($subset != 0) {
    my $err = `cat $temp_dir/$job_num.subset.err`;
    fail($log, $err);
}

# cleanup
my @out = glob "$temp_dir/$job_num.*.out";
my @err = glob "$temp_dir/$job_num.*.err";
if (scalar(@out)) {
    system("cat ".join(" ", @out)." > $run_dir/output.log");
    system("rm -f ".join(" ", @out));
}
if (scalar(@err)) {
    system("cat ".join(" ", @err)." > $run_dir/error.log");
    system("rm -f ".join(" ", @err));
}

# update jobcache stage status
Pipeline::update_stage_info($job_num, $stage_name, "completed");
$log->info("Finished $stage_name on job: $job_num");

exit(0);

sub fail {
  my ($log, $message) = @_;
  Pipeline::update_stage_info($job_num, $stage_name, "error");
  $log->error($message);
  exit(1);
}

