#!/usr/bin/env perl 

use strict;
use warnings;
no warnings('once');

use Pipeline;
use Pipeline_Conf;

use Getopt::Long;
use File::Copy;
use File::Basename;
use POSIX qw(strftime);
umask 000;

my $stage_name="dereplication";
my $stage;
for my $s (@{$Pipeline_Conf::pipeline->{'default'}}) {
  $stage = $s if $s->{name} eq $stage_name; 
}
my $stage_id = $stage->{id};
my $revision = "0";
my $version  = $Pipeline_Conf::pipeline_version.".".$revision;
my $runcmd   = "dereplication";

# options
my $job_num    = "";
my $fasta_file = "";
my $run_derep  = 1;
my $prefix_size = 50;
my $ver     = "";
my $help    = "";
my $options = GetOptions ("job=i"       => \$job_num,
			  "fasta=s"     => \$fasta_file,
			  "prefix_length=i" => \$prefix_size,
			  "run_derep=i" => \$run_derep,
			  "version"     => \$ver,
			  "help"        => \$help
			 );

if ( $ver ) {
  print STDERR "$stage_name - $version - $stage_id\n";
  exit(0);
} elsif ( $help or !($job_num and $fasta_file) ) {
  print STDERR "Usage: pipeline_$stage_name -j <job number> -f <fasta file> -r <run dereplication> [-p <prefix length>]\n";
  exit(1);
} 

my $log = Pipeline::logger($job_num);

unless (-s $fasta_file) {
  $log->error("file: $fasta_file does not exist or is empty");
  exit(1);
}

$log->info("Starting $stage_name on job: $job_num");

# update jobcache stage status
Pipeline::update_stage_info($job_num, $stage_name, "running");

my $job_dir     = $Pipeline_Conf::global_job_dir."/".$job_num;
my $proc_dir    = $job_dir."/proc";
my $stage_dir   = $proc_dir."/".$stage_id.".".$stage_name;
my $results_dir = $job_dir."/".$Pipeline_Conf::results_dir;
my $run_dir     = $stage_dir;
my $hostname    = `hostname`;
chomp $hostname;

# create directories
if (-d $stage_dir) {
  my $t = time;
  $log->info("found $stage_dir, moving to $stage_dir.$t");
  move($stage_dir, $stage_dir.".".$t) or fail($log, "$!");
}
mkdir($stage_dir) or fail($log, "Could not mkdir: $stage_dir, $!");

# set cluster workspace dir
if (-d $Pipeline_Conf::cluster_workspace) {
  $run_dir = $Pipeline_Conf::cluster_workspace . "/$job_num.$stage_id.$stage_name";
  if (-d $run_dir) {
    system("rm -rf $run_dir");
  }
  mkdir($run_dir) or fail($log, "Could not mkdir: $run_dir, $!");
  system("echo $hostname > $stage_dir/hostname");
}
$log->info("Running on host $hostname, using dir $run_dir");

my $sort_dir    = (-d $Pipeline_Conf::local_tmp) ? $Pipeline_Conf::local_tmp : ((-d $Pipeline_Conf::cluster_tmp) ? $Pipeline_Conf::cluster_tmp : $run_dir);
my $input_fasta = $stage_id.".".$stage_name.".input.fna";
my $passed_seq  = $stage_id.".".$stage_name.".passed.fna";
my $removed_seq = $stage_id.".".$stage_name.".removed.fna";
my $derep_map   = $stage_id.".".$stage_name.".mapping";

if ($run_derep) {
  # run cmd
  system("cp $fasta_file $run_dir/$input_fasta >> $run_dir/$runcmd.out 2>&1") == 0 or fail($log, "Dereplication failed on job: $job_num, see $stage_dir/$runcmd.out for details.");
  system("$runcmd -p $prefix_size -f $run_dir/$input_fasta -dest $run_dir -m 2500M -t $sort_dir >> $run_dir/$runcmd.out 2>&1") == 0 or fail($log, "Dereplication failed on job: $job_num, see $stage_dir/$runcmd.out for details.");
  system("cut -f1,2 $run_dir/$input_fasta.prefix_$prefix_size.sorted > $run_dir/$derep_map") == 0 or fail($log, "Dereplication failed on job: $job_num, unable to parse output");

  # copy output to somewhere
  move($run_dir."/".$input_fasta.".derep.fasta", $results_dir."/".$passed_seq) or fail($log, "Failed copy $input_fasta.derep.fasta - $!");
  move($run_dir."/".$input_fasta.".removed.fasta", $results_dir."/".$removed_seq) or fail($log, "Failed copy $input_fasta.removed.fasta - $!");
  move($run_dir."/".$derep_map, $results_dir."/".$derep_map) or fail($log, "Failed copy $derep_map - $!");

  if ($run_dir ne $stage_dir) {
    move("$run_dir/$runcmd.out", "$stage_dir/$runcmd.out") or fail($log, "Failed copy file: $runcmd.out - $!");
    system("rm -rf $run_dir") == 0 or fail($log, "$stage_name failed on job: $job_num, can not remove $run_dir");
  } else {
    my @run_files = `ls $run_dir`;
    chomp @run_files;
    map { system("rm $run_dir/$_") } grep { $_ !~ /\.out$/ } @run_files;
  }
}
else {
  copy($fasta_file, $results_dir."/".$passed_seq) or fail($log, "Failed copy $fasta_file - $!");
  system("touch $results_dir/$removed_seq");
  system("touch $results_dir/$derep_map");
  if ($run_dir ne $stage_dir) {
    system("rmdir $run_dir") == 0 or fail($log, "$stage_name failed on job: $job_num, can not remove $run_dir");
  }
}

open(INFO, ">".$results_dir."/".$stage_id.".".$stage_name.".info");
print INFO "# MG-RAST - ".$stage_name." v".$version." - (".(strftime "%b %e %Y", localtime).")\n";
print INFO "# site : metagenomics.anl.gov\n# email: mg-rast\@mcs.anl.gov\n";
print INFO ($run_derep ? $runcmd : "skipped $stage_name") . "\n";
close(INFO);

chmod 0666, $results_dir."/".$stage_id.".".$stage_name.".info";
chmod 0666, $results_dir."/".$passed_seq;
chmod 0666, $results_dir."/".$removed_seq;

$log->info("Finished $stage_name on job: $job_num");

# update jobcache stage status
Pipeline::update_stage_info($job_num, $stage_name, "completed");

exit(0);

sub fail {
  my ($log, $message) = @_;
  Pipeline::update_stage_info($job_num, $stage_name, "error");
  $log->error($message);
  if ($run_dir ne $stage_dir) {
    system("mv $run_dir/* $stage_dir/.");
    system("rmdir $run_dir");
  }
  exit(1);
}
