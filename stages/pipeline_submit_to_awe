#!/usr/bin/env perl 

#MG-RAST pipeline job submitter for AWE
#Command name: pipeline_submit_to_awe
#Options:
#     -job_num=<job number, required>
#     -upload=<input file that is local and to be uploaded, required>
#     -pipeline=<path for pipeline job template, required>
#     -pipeline_token=<globus token for authentication, required>
#     -awe=<AWE server URL (ip:port), required>
#     -shock=<Shock URL (ip:port), required>
#     -mem_host=<memcache URL (ip:port), required>
#     -name=<job name (default='default')>
#     -user=<user name (default='mgrastprod')>
#     -project=<project name (default='pipeline')>
#     -cgroups=<exclusive_client_group_list (separate by ',') (default='')>
#     -totalwork_sm=<number of workunits to split for splitable tasks of small jobs (default 8)>
#     -totalwork_lg=<number of workunits to split for splitable tasks of large jobs (default 16)>
#     -lg_size=<cutoff for size in bytes that categorizes a job as large (default 2147483648 bytes, aka 2GB)>
#     -bowtie=<boolean, if bowtie should be run (default 1)>
#     -dereplicate=<boolean, if dereplication should be performed (default 1)>
#     -filter_options=<default='filter_ambig:max_ambig=5:filter_ln:min_ln=1:max_ln=806'>
#     -screen_indexes=<default=none>
#     
#Use case: submit a job with a local input file and a pipeline template (input file is local and will be uploaded to shock automatially;
#      Required options: -upload, -pipeline (if awe_pipeline_template not in Pipeline_Conf.pm), -pipeline_token (if awe_pipeline_token not in Pipeline_Conf.pm, -awe (if awe_url not in Pipeline_Conf.pm), -shock (if shock_url not in Pipeline_Conf.pm)
#      Optional options: -name, -user, -project, -cgroups, -totalwork_sm, -totalwork_lg, -lg_size, -bowtie, -dereplicate, -filter_options, -screen_indexes
#      Operations:
#               1. upload input file to shock
#               2. create job script based on job template and available info
#               3. submit the job json script to awe
#               
#Note: if awe_pipeline_template, awe_pipeline_token, awe_url (ip:port), shock_url (ip:port), and mem_host_url (ip:port) are configured in Pipeline_Conf.pm, -pipeline, -pipeline_token, -awe, -shock, and -mem_host are not needed respectively. But the specified command line options will override the Pipeline_Conf.pm variables.

use strict;
use warnings;
no warnings('once');

use Pipeline;
use Pipeline_Conf;

use DBI;
use JSON;
use Digest::MD5::File qw( file_md5_hex );
use File::Slurp;
use Getopt::Long;
use LWP::UserAgent;
use String::Random;
use Data::Dumper;
umask 000;

my $stage_name = "submit_to_awe";
my $stage;
for my $s (@{$Pipeline_Conf::pipeline->{'awe_part_one'}}){
  $stage = $s if $s->{name} eq $stage_name;
}
my $stage_id = $stage->{id};

# options
my $job_num = "";
my %vars = ();  # Hash to store variables that we'll replace in the AWE job template
$vars{inputfile} = "";
my $awe_url = "";
$vars{shockurl} = "";
$vars{mem_host} = "";
my $pipeline_token = "";
my $pipeline_template = "";
$vars{jobname} ="default";
$vars{user} = "mgrastprod";
$vars{project} = "pipeline";
$vars{clientgroups} = "";
my $totalwork_sm = 8;
my $totalwork_lg = 16;
my $lg_size = 2147483648;
$vars{bowtie} = 1;
$vars{dereplicate} = 1;
$vars{filter_options} = "filter_ambig:max_ambig=5:filter_ln:min_ln=1:max_ln=806";
$vars{screen_indexes} = "";
$vars{predata} = "";

my $help = 0;

my $options = GetOptions ("job_num=i" => \$job_num,
                          "upload=s"   => \$vars{inputfile},
			  "pipeline=s" => \$pipeline_template,
			  "pipeline_token=s" => \$pipeline_token,
                          "awe=s"    => \$awe_url,
 			  "shock=s"  => \$vars{shockurl},
                          "mem_host=s" => \$vars{mem_host},
                          "name=s" => \$vars{jobname},
                          "user=s"   => \$vars{user},
                          "project=s" => \$vars{project},
                          "cgroups=s" => \$vars{clientgroups},
                          "totalwork_sm=i" => \$totalwork_sm,
                          "totalwork_lg=i" => \$totalwork_lg,
                          "lg_size=i" => \$lg_size,
                          "bowtie=i" => \$vars{bowtie},
                          "dereplicate=i" => \$vars{dereplicate},
                          "filter_options=s" => \$vars{filter_options},
                          "screen_indexes=s" => \$vars{screen_indexes},
                          "h"  => \$help,
			 );

$vars{aa_pid} = 90;
$vars{ach_annotation_ver} = length($Pipeline_Conf::ach_annotation_ver) > 0 ? $Pipeline_Conf::ach_annotation_ver : 1;
$vars{fgs_type} = 454;
$vars{md5rna_clust} = length($Pipeline_Conf::md5rna_clust) > 0 ? $Pipeline_Conf::md5rna_clust : "md5nr.clust";
$vars{md5rna_clust} =~ s/.*\/(.*)/$1/;
$vars{prefix_length} = 50;
$vars{rna_pid} = 97;

if ($help) {
    print_usage();
    exit 0;
}

if(length($job_num)==0) {
    print STDERR "$stage_name failed, job_num was not specified.\n";
    print_usage();
    exit 1;
}

my $log = Pipeline::logger($job_num);
$log->info("Starting $stage_name on job: $job_num");

if (length($vars{inputfile})==0) {
    $log->error("$stage_name failed on job: $job_num, please specify the local path of the input file.");
    print_usage();
    exit 1;
} elsif (! -e $vars{inputfile}) {
    $log->error("$stage_name failed on job: $job_num, the input file [".$vars{inputfile}."] does not exist.");
    print_usage();
    exit 1;  
}

if (length($pipeline_template)==0) {
    $pipeline_template = $Pipeline_Conf::awe_pipeline_template;
    if (length($pipeline_template)==0) {
        $log->error("$stage_name failed on job: $job_num, a pipeline template was not specified.");
        print_usage();
        exit 1;  
    } elsif (! -e $pipeline_template) {
        $log->error("$stage_name failed on job: $job_num, the pipeline template file [$pipeline_template] does not exist.");
        print_usage();
        exit 1;
    }
}
    
if (length($pipeline_token)==0) {
    $pipeline_token = $Pipeline_Conf::awe_pipeline_token;
    if (length($pipeline_token)==0) {
        $log->error("$stage_name failed on job: $job_num, a pipeline token was not specified.");
        print_usage();
        exit 1;
    }
}

if (length($awe_url)==0) {
    $awe_url = $Pipeline_Conf::awe_url;
    if (length($awe_url)==0) {
        $log->error("$stage_name failed on job: $job_num, the AWE server URL was not specified.");
        print_usage();
        exit 1;
    }
}

if (length($vars{shockurl})==0 ) {
    $vars{shockurl} = $Pipeline_Conf::shock_url;
    if (length($vars{shockurl})==0) {
        $log->error("$stage_name failed on job: $job_num, the Shock server URL was not specified.");
	print_usage();
	exit 1;
    }
}

if (length($vars{mem_host})==0 ) {
    $vars{mem_host} = $Pipeline_Conf::mem_host_url;
    if (length($vars{mem_host})==0) {
        $log->error("$stage_name failed on job: $job_num, the memcache server URL was not specified.");
	print_usage();
	exit 1;
    }
}

if (length($vars{screen_indexes}) > 0) {
    my $index_files = &get_bowtie_shock_ids($vars{screen_indexes});
    my $file_count = keys %{$index_files};
    if ($file_count == 0) {
        $log->error("$stage_name failed on job: $job_num, there are no screen indexes for ".$vars{screen_indexes}.".");
        print_usage();
        exit 1;
    }
    foreach my $filename (keys %{$index_files}) {
        if($vars{predata} ne "") {
            $vars{predata} .= ",\n                    ";
        }
        $vars{predata} .= "\"$filename\":{\n".
                          "                        \"url\":\"http://".$Pipeline_Conf::shock_url."/node/".$index_files->{$filename}."?download\"\n".
                          "                    }";
    }
}

$vars{md5nr1_download_url} = "http://".$Pipeline_Conf::shock_url."/node/5fb38b95-ae49-44ed-bbf6-f135ad397993?download";
$vars{md5nr2_download_url} = "http://".$Pipeline_Conf::shock_url."/node/a4fd51d7-97c1-400c-9278-12087b930f7e?download";
$vars{md5rna_clust_download_url} = "http://".$Pipeline_Conf::shock_url."/node/f9761860-dc49-49c7-8de1-d3e3708802d2?download";
$vars{md5rna_download_url} = "http://".$Pipeline_Conf::shock_url."/node/d25932bf-83ed-44cf-8696-5bfeb6c8c8ef?download";

my $job_dir   = $Pipeline_Conf::global_job_dir."/".$job_num;
my $proc_dir  = $job_dir."/proc";
my $stage_dir = $proc_dir."/".$stage_id.".".$stage_name;
mkdir($stage_dir) or fail($log, "Could not mkdir: $stage_dir, $!");

#upload input to shock
$log->info("Uploading input file: ".$vars{inputfile}." to Shock");

my $md5 = file_md5_hex( $vars{inputfile} );
my $ua = LWP::UserAgent->new();

$HTTP::Request::Common::DYNAMIC_FILE_UPLOAD = 1;
my $post = $ua->post("http://".$Pipeline_Conf::shock_url_from_mgrast."/node",
                     Content_Type  => 'form-data',
                     Content       => [ upload => [$vars{inputfile}] ],
                     Authorization => "OAuth $pipeline_token"
                    );

my $json = new JSON();
my $res = $json->decode( $post->content );
my $res_md5 = $res->{data}->{file}->{checksum}->{md5};
$vars{shocknode} = $res->{data}->{id};

if($md5 ne $res_md5) {
    $log->error("$stage_name failed on job: $job_num, Shock upload of input file to Shock node:".$vars{shocknode}." was not successful.");
    exit(1);
}

$log->info("Upload of input file: ".$vars{inputfile}." complete. Shock node id=".$vars{shocknode}."\n");

#generate job script based on template (instantiate a job script with availalbe information filled into the template)
my $pipeline_name = $pipeline_template;
$pipeline_name =~ s/(.*)\.template/$1/;
if (length($vars{jobname})==0) {
    $vars{jobname} = $pipeline_name.".job";
}

# setting totalwork variable
my $file_size = -s $vars{inputfile};
if($file_size >= $lg_size) {
    $vars{totalwork} = $totalwork_lg;
} else {
    $vars{totalwork} = $totalwork_sm;
}

# inputfile in awe workflow cannot contain directory path, only filename, so removing path here.
$vars{inputfile} =~ s/.*\/(.*)/$1/;

# Replace # vars in template
my $text = read_file($pipeline_template);
foreach my $key (keys %vars) {
    $text =~ s/#$key/$vars{$key}/g;
}

my $jobscript = "$stage_dir/awe_workflow.$job_num.json";
open OUT, ">$jobscript" || fail($log, "Could not open $jobscript for writing.");
print OUT $text;
close OUT;

#upload job script to awe server
$log->info("Submitting job script ($jobscript) to AWE.\n");
$ua = LWP::UserAgent->new();
$post = $ua->post("http://".$awe_url."/job",
                  Content_Type => 'form-data',
                  Content      => [ upload => [$jobscript] ],
                  Datatoken    => $pipeline_token
                 );

$res = $json->decode( $post->content );

my $awe_id = $res->{data}->{id};
my $job_id = $res->{data}->{jid};
my $state = $res->{data}->{state};

my $awe_dump_file = "$stage_dir/awe_submission_output.txt";

open OUT, ">$awe_dump_file" || fail($log, "Could not open $awe_dump_file for writing.");
print OUT Dumper($res);
close OUT;

if($state ne "submitted") {
    $log->error("$stage_name failed on job: AWE job submission was not successful, please see '$awe_dump_file' for more info.");
    exit(1);
}

print " Done! awe_id=".$awe_id." job_id=$job_id\n";
$log->info("AWE submission complete. AWE URL = http://".$awe_url."/job/".$awe_id." Shock URL = http://".$Pipeline_Conf::shock_url_from_mgrast."/node/".$vars{shocknode});

$log->info("Adding job to AWE MG-RAST lookup database.");
my $db = $Pipeline_Conf::awe_mgrast_lookup_db;
my $host = $Pipeline_Conf::awe_mgrast_lookup_host;
my $user = $Pipeline_Conf::awe_mgrast_lookup_user;
my $pass = $Pipeline_Conf::awe_mgrast_lookup_pass;
my $table = $Pipeline_Conf::awe_mgrast_lookup_table;
my $dbh = DBI->connect("DBI:mysql:$db;host=$host", $user, $pass) || fail($log, "Couldn't connect to database: ".DBI->errstr);
my $str = "INSERT INTO $table (job, awe_id, awe_url, status, submitted, last_update) VALUES($job_num, '$awe_id', 'http://$awe_url/job/$awe_id', '$state', now(), now())";
my $sth = $dbh->prepare($str) || fail($log, "Couldn't prepare statement: " . $dbh->errstr);
$sth->execute() || fail($log, "Couldn't execute statement: " . $sth->errstr);

$log->info("Job added to AWE MG-RAST lookup database.");
$log->info("Finished $stage_name on job: $job_num");

exit(0);

sub fail {
    my ($log, $message) = @_;
    Pipeline::update_stage_info($job_num, $stage_name, "error");
    $log->error($message);
    exit(1);
}

sub print_usage{
    print "
MG-RAST pipeline job submitter for AWE
Command name: pipeline_submit_to_awe
Options:
     -job_num=<job number, required>
     -upload=<input file that is local and to be uploaded, required>
     -pipeline=<path for pipeline job template, required>
     -pipeline_token=<globus token for authentication, required>
     -awe=<AWE server URL (ip:port), required>
     -shock=<Shock URL (ip:port), required>
     -mem_host=<memcache URL (ip:port), required>
     -name=<job name (default='default')>
     -user=<user name (default='mgrastprod')>
     -project=<project name (default='pipeline')>
     -cgroups=<exclusive_client_group_list (separate by ',') (default='')>
     -totalwork_sm=<number of workunits to split for splitable tasks of small jobs (default 8)>
     -totalwork_lg=<number of workunits to split for splitable tasks of large jobs (default 16)>
     -lg_size=<cutoff for size in bytes that categorizes a job as large (default 2147483648 bytes, aka 2GB)>
     -bowtie=<boolean, if bowtie should be run (default 1)>
     -dereplicate=<boolean, if dereplication should be performed (default 1)>
     -filter_options=<default='filter_ambig:max_ambig=5:filter_ln:min_ln=1:max_ln=806'>
     -screen_indexes=<default=none>
     
Use case: submit a job with a local input file and a pipeline template (input file is local and will be uploaded to shock automatially
      Required options: -upload, -pipeline (if awe_pipeline_template not in Pipeline_Conf.pm), -pipeline_token (if awe_pipeline_token not in Pipeline_Conf.pm, -awe (if awe_url not in Pipeline_Conf.pm), -shock (if shock_url not in Pipeline_Conf.pm)
      Optional options: -name, -user, -project, -cgroups, -totalwork_sm, -totalwork_lg, -lg_size, -bowtie, -dereplicate, -filter_options, -screen_indexes
      Operations:
               1. upload input file to shock
               2. create job script based on job template and available info
               3. submit the job json script to awe
               
Note: if awe_pipeline_template, awe_pipeline_token, awe_url (ip:port), shock_url (ip:port), and mem_host_url (ip:port) are configured in Pipeline_Conf.pm, -pipeline, -pipeline_token, -awe, -shock, and -mem_host are not needed respectively. But the specified command line options will override the Pipeline_Conf.pm variables.\n";
}

sub get_bowtie_shock_ids {
    my $index = shift;
    my $bowtie_shock_indexes = {
        a_thaliana            => { "a_thaliana.1.ebwt" => "b53122f0-08fc-4247-8284-3294325cb177",
                                   "a_thaliana.2.ebwt" => "d8a053ef-a818-404e-8bd2-892beca29ce3",
                                   "a_thaliana.3.ebwt" => "6afb98fc-4218-47c4-99d9-19626cae82e5",
                                   "a_thaliana.4.ebwt" => "62573b46-472a-4436-9ba9-f1d1334604dc",
                                   "a_thaliana.rev.1.ebwt" => "a769936c-4e70-4411-8603-72b68f45dfe8",
                                   "a_thaliana.rev.2.ebwt" => "c0eb7d3f-c57b-489b-bab2-7032bc91638f"
                                 },
        b_taurus              => { "b_taurus.1.ebwt" => "d954a597-6e7f-4bee-95c4-4550f4e5dbf6",
                                   "b_taurus.2.ebwt" => "38bfe05a-b5fd-4e33-be34-b2eb98a1432c",
                                   "b_taurus.3.ebwt" => "5c3f69b6-1c57-4109-ad13-e77f783ee33f",
                                   "b_taurus.4.ebwt" => "bc50616e-d4ee-4e2c-8e66-4114bcc1c31b",
                                   "b_taurus.rev.1.ebwt" => "96d69336-9e61-4bf2-a2cf-1f8628f094a3",
                                   "b_taurus.rev.2.ebwt" => "ee4f0cd5-4180-42ae-a541-afefff09c33b"
                                 },
        d_melanogaster_fb5_22 => { "d_melanogaster_fb5_22.1.ebwt" => "e3abc9e4-80db-40c9-89f4-b6bfe2faa96b",
                                   "d_melanogaster_fb5_22.2.ebwt" => "b7a9e967-9567-4311-bf3c-305fd09172bd",
                                   "d_melanogaster_fb5_22.3.ebwt" => "5ef733e0-9d69-4e0b-a6b6-0540509f56b9",
                                   "d_melanogaster_fb5_22.4.ebwt" => "08ef7f52-cced-4e61-9308-f75e2ff2f8cf",
                                   "d_melanogaster_fb5_22.rev.1.ebwt" => "df73238b-d5f9-4e77-a405-b399dda7b15b",
                                   "d_melanogaster_fb5_22.rev.2.ebwt" => "61f933a3-70c8-4444-b22d-78abb757bdec"
                                 },
        e_coli                => { "e_coli.1.ebwt" => "67c9fc34-02fd-4fb0-ad09-ae475a1fdee8",
                                   "e_coli.2.ebwt" => "c21178ea-2337-4a54-bf04-9c473a725d87",
                                   "e_coli.3.ebwt" => "cbf1f1c3-7ca7-4be4-b2b1-c3e0044837ed",
                                   "e_coli.4.ebwt" => "ce4fabb0-a1d8-48c2-bddf-f92c79409efe",
                                   "e_coli.rev.1.ebwt" => "b1199622-35a1-415e-a05b-8ddd09bc9306",
                                   "e_coli.rev.2.ebwt" => "bcd3362d-90f1-4835-aa54-f487e79dde65"
                                 },
        h_sapiens_asm         => { "h_sapiens_asm.1.ebwt" => "23548abb-2764-4a8a-82fd-e07b740bab94",
                                   "h_sapiens_asm.2.ebwt" => "c76dda7e-4976-4cde-9224-704bfa39185e",
                                   "h_sapiens_asm.3.ebwt" => "0251fc52-a12a-4ca7-8509-c388749afcee",
                                   "h_sapiens_asm.4.ebwt" => "c59876d4-cf8f-453f-9c54-a68495dc64db",
                                   "h_sapiens_asm.rev.1.ebwt" => "a818ac51-c07f-4151-91d4-323195d405b1",
                                   "h_sapiens_asm.rev.2.ebwt" => "20ceaa17-1649-404c-8516-ef112d92c504"
                                 },
        m_musculus_ncbi37     => { "m_musculus_ncbi37.1.ebwt" => "426ee5fc-41bb-406e-b103-ba858f1eb304",
                                   "m_musculus_ncbi37.2.ebwt" => "e0f0e549-bd36-4f36-8145-6fc0a766e3e4",
                                   "m_musculus_ncbi37.3.ebwt" => "168d9ab4-07a2-4a1d-b558-c7d456925c06",
                                   "m_musculus_ncbi37.4.ebwt" => "add3270b-0995-4759-a853-c95743675474",
                                   "m_musculus_ncbi37.rev.1.ebwt" => "f8f79b47-a63d-4c69-87d8-7f1b8a45fe87",
                                   "m_musculus_ncbi37.rev.2.ebwt" => "6e5ca6e2-bcfd-4298-a32e-03f5f8be8dee"
                                 },
        's_scrofa_ncbi10.2'   => { "s_scrofa_ncbi10.2.1.ebwt" => "d93015b2-a086-429a-9fa9-a923d6b12cf2",
                                   "s_scrofa_ncbi10.2.2.ebwt" => "96df194e-ac14-42e1-9435-80c29660c250",
                                   "s_scrofa_ncbi10.2.3.ebwt" => "9014930a-93d7-4428-992f-6311f4f6a659",
                                   "s_scrofa_ncbi10.2.4.ebwt" => "e75b5129-2788-4a93-91d3-b3345bc4dd7b",
                                   "s_scrofa_ncbi10.2.rev.1.ebwt" => "ec54b8bd-f9bb-40b4-9730-b06c18335a07",
                                   "s_scrofa_ncbi10.2.rev.2.ebwt" => "dea771b7-da7e-48f9-9f86-3d6fee6a63dd"
                                 }
    };
    if(exists $bowtie_shock_indexes->{$index}) {
        return $bowtie_shock_indexes->{$index};
    }
    return {};
}
